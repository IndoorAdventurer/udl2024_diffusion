{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development\n",
    "For experimenting with stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First getting dataset\n",
    "Copying this from that example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "\n",
    "dataset_path = './datasets'\n",
    "\n",
    "cuda = True\n",
    "DEVICE = \"cpu\" # torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "img_size = (32, 32, 3)   if dataset == \"CIFAR10\" else (28, 28, 1) # (width, height, channels)\n",
    "\n",
    "timestep_embedding_dim = 256\n",
    "n_layers = 8\n",
    "hidden_dim = 256\n",
    "n_timesteps = 1000\n",
    "beta_minmax=[1e-4, 2e-2]\n",
    "\n",
    "train_batch_size = 1\n",
    "inference_batch_size = 1\n",
    "lr = 5e-5\n",
    "epochs = 200\n",
    "\n",
    "seed = 1234\n",
    "\n",
    "hidden_dims = [hidden_dim for _ in range(n_layers)]\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "if dataset == 'CIFAR10':\n",
    "    train_dataset = CIFAR10(dataset_path, transform=transform, train=True, download=True)\n",
    "    test_dataset  = CIFAR10(dataset_path, transform=transform, train=False, download=True)\n",
    "else:\n",
    "    train_dataset = MNIST(dataset_path, transform=transform, train=True, download=True)\n",
    "    test_dataset  = MNIST(dataset_path, transform=transform, train=False, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=train_batch_size, shuffle=True, **kwargs)\n",
    "test_loader  = DataLoader(dataset=test_dataset,  batch_size=inference_batch_size, shuffle=False,  **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying their code to see expected behavior\n",
    "After that I will replicate it to see if mine gives exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheirCode:\n",
    "    def __init__(self, model, image_resolution=[32, 32, 3], n_times=1000, beta_minmax=[1e-4, 2e-2], device='cuda'):\n",
    "    \n",
    "        self.n_times = n_times\n",
    "        self.img_H, self.img_W, self.img_C = image_resolution\n",
    "\n",
    "        # self.model = model\n",
    "        \n",
    "        # define linear variance schedule(betas)\n",
    "        beta_1, beta_T = beta_minmax\n",
    "        betas = torch.linspace(start=beta_1, end=beta_T, steps=n_times).to(device) # follows DDPM paper\n",
    "        self.sqrt_betas = torch.sqrt(betas)\n",
    "                                     \n",
    "        # define alpha for forward diffusion kernel\n",
    "        self.alphas = 1 - betas\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1-alpha_bars)\n",
    "        self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
    "        \n",
    "        self.device = device\n",
    "    \n",
    "    def extract(self, a, t, x_shape):\n",
    "        \"\"\"\n",
    "            from lucidrains' implementation\n",
    "                https://github.com/lucidrains/denoising-diffusion-pytorch/blob/beb2f2d8dd9b4f2bd5be4719f37082fe061ee450/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L376\n",
    "        \"\"\"\n",
    "        b, *_ = t.shape\n",
    "        out = a.gather(-1, t)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "    \n",
    "    def scale_to_minus_one_to_one(self, x):\n",
    "        # according to the DDPMs paper, normalization seems to be crucial to train reverse process network\n",
    "        return x * 2 - 1\n",
    "    \n",
    "    def reverse_scale_to_zero_to_one(self, x):\n",
    "        return (x + 1) * 0.5\n",
    "    \n",
    "    def make_noisy(self, x_zeros, t): \n",
    "        # perturb x_0 into x_t (i.e., take x_0 samples into forward diffusion kernels)\n",
    "        epsilon = torch.randn_like(x_zeros).to(self.device)\n",
    "        \n",
    "        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars, t, x_zeros.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, t, x_zeros.shape)\n",
    "        \n",
    "        # Let's make noisy sample!: i.e., Forward process with fixed variance schedule\n",
    "        #      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon\n",
    "        noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n",
    "    \n",
    "        return noisy_sample.detach(), epsilon\n",
    "    \n",
    "    \n",
    "    def forward(self, x_zeros):\n",
    "        x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n",
    "        \n",
    "        B, _, _, _ = x_zeros.shape\n",
    "        \n",
    "        # (1) randomly choose diffusion time-step\n",
    "        t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(self.device)\n",
    "        \n",
    "        # (2) forward diffusion process: perturb x_zeros with fixed variance schedule\n",
    "        perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n",
    "        \n",
    "        # (3) predict epsilon(noise) given perturbed data at diffusion-timestep t.\n",
    "        pred_epsilon = self.model(perturbed_images, t)\n",
    "        \n",
    "        return perturbed_images, epsilon, pred_epsilon\n",
    "    \n",
    "    \n",
    "    def denoise_at_t(self, x_t, timestep, t):\n",
    "        B, _, _, _ = x_t.shape\n",
    "        if t > 1:\n",
    "            z = torch.randn_like(x_t).to(self.device)\n",
    "        else:\n",
    "            z = torch.zeros_like(x_t).to(self.device)\n",
    "        \n",
    "        # at inference, we use predicted noise(epsilon) to restore perturbed data sample.\n",
    "        epsilon_pred = self.model(x_t, timestep)\n",
    "        \n",
    "        alpha = self.extract(self.alphas, timestep, x_t.shape)\n",
    "        sqrt_alpha = self.extract(self.sqrt_alphas, timestep, x_t.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, timestep, x_t.shape)\n",
    "        sqrt_beta = self.extract(self.sqrt_betas, timestep, x_t.shape)\n",
    "        \n",
    "        # denoise at time t, utilizing predicted noise\n",
    "        x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1-alpha)/sqrt_one_minus_alpha_bar*epsilon_pred) + sqrt_beta*z\n",
    "        \n",
    "        return x_t_minus_1.clamp(-1., 1)\n",
    "                \n",
    "    def sample(self, N):\n",
    "        # start from random noise vector, x_0 (for simplicity, x_T declared as x_t instead of x_T)\n",
    "        x_t = torch.randn((N, self.img_C, self.img_H, self.img_W)).to(self.device)\n",
    "        \n",
    "        # autoregressively denoise from x_T to x_0\n",
    "        #     i.e., generate image from noise, x_T\n",
    "        for t in range(self.n_times-1, -1, -1):\n",
    "            timestep = torch.tensor([t]).repeat_interleave(N, dim=0).long().to(self.device)\n",
    "            x_t = self.denoise_at_t(x_t, timestep, t)\n",
    "        \n",
    "        # denormalize x_0 into 0 ~ 1 ranged values.\n",
    "        x_0 = self.reverse_scale_to_zero_to_one(x_t)\n",
    "        \n",
    "        return x_0\n",
    "    \n",
    "    \n",
    "theircode = TheirCode(None, image_resolution=img_size, n_times=n_timesteps, \n",
    "                      beta_minmax=beta_minmax, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1996\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch[0] = theircode.scale_to_minus_one_to_one(batch[0])\n",
    "\n",
    "for idx in [100 * x + 1 for x in range(10)] + [999]:\n",
    "    img = theircode.make_noisy(batch[0], torch.tensor([idx]))[0]\n",
    "    img = theircode.reverse_scale_to_zero_to_one(img).squeeze()\n",
    "    plt.imshow(img.detach().permute(1, 2, 0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Class\n",
    "Here I will create my noising class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionNoiser(nn.Module):\n",
    "    \"\"\"A class to define the noising process. Will have methods to add noise\n",
    "    in the closed and open form to images, but also inverse operations, such as\n",
    "    removing (predicted) noise from an image, or sampling a new image.\n",
    "    \n",
    "    My convention for indexing is as follows:\n",
    "    - t=0 is the original image.\n",
    "    - t=steps(1000) should be pure gaussian noise\n",
    "    - take image of step t and alphas/betas of step t to go to t+1\n",
    "    - this means alphas and betas go from t=0 to t=steps(1000)-1\n",
    "\n",
    "    Turned it into a nn.Module such that I don't need to worry about putting\n",
    "    tensors on the correct device, etc.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(   self,\n",
    "                    steps: int = 1000,\n",
    "                    beta_start: float = 1e-4,\n",
    "                    beta_end: float = 0.02\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            steps: number of noising steps to use\n",
    "            beta_start: todo\n",
    "            beta_end: todo\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        betas = torch.linspace(beta_start, beta_end, steps)\n",
    "        alpha_bars = torch.cumprod(1 - betas, 0)\n",
    "\n",
    "        self.register_buffer(\"betas\", betas)\n",
    "        self.register_buffer(\"alpha_bars\", alpha_bars)\n",
    "    \n",
    "    def forward(self, img, noise, t):\n",
    "        \"\"\"Calls DiffusionNoiser.closed_form_noise().\"\"\"\n",
    "        return self.closed_form_noise(img, noise, t)\n",
    "\n",
    "    def closed_form_noise(self, img, noise, t):\n",
    "        \"\"\"Adds noise to an image using the DDPM closed form formula.\n",
    "\n",
    "        Args:\n",
    "            img: The image(s) to add noise to [(B x) C x H x W].\n",
    "            noise: the gaussian noise to add N(0,1) [(B x) C x H x W].\n",
    "            t: integer time step (single integer or shape [B,])\n",
    "        \"\"\"\n",
    "        alpha_bar = self.alpha_bars[t]\n",
    "        return torch.sqrt(alpha_bar) * img + torch.sqrt(1 - alpha_bar) * noise\n",
    "\n",
    "    def noise_from_closed_form_noise(self, img, noised_img, t):\n",
    "        \"\"\"Inverse of closed_form_noise: returns the noise, given the original\n",
    "        imaged and a noised version.\n",
    "        \n",
    "        Args:\n",
    "            img: the original image.\n",
    "            noised_img: a noised version of the image.\n",
    "            t: the timestep used to get from img to noised_img.\n",
    "        \"\"\"\n",
    "        alpha_bar = self.alpha_bars[t]\n",
    "        return (noised_img - torch.sqrt(alpha_bar) * img) / torch.sqrt(1 - alpha_bar)\n",
    "    \n",
    "    def img_from_closed_form_noise(self, noised_img, noise, t):\n",
    "        \"\"\"Inverse of closed_form_noise: returns the original image, given the\n",
    "        noise and a noised version of the image.\n",
    "        \n",
    "        Args:\n",
    "            noised_img: a noised version of the image.\n",
    "            noise: the noise that was added to get noised_img.\n",
    "            t: the timestep used to get from imgage to noised_img using noise.\n",
    "        \"\"\"\n",
    "        alpha_bar = self.alpha_bars[t]\n",
    "        return (noised_img - torch.sqrt(1 - alpha_bar) * noise ) / torch.sqrt(alpha_bar)\n",
    "    \n",
    "    def forward_noise_step(self, img_prev, noise, t):\n",
    "        \"\"\"The forward noising process in a step-wise manner: computes a\n",
    "        slightly noisier image from img_prev.\n",
    "        \n",
    "        Args:\n",
    "            img_prev: image corresponding to step t.\n",
    "            noise: the noise to add to get to step t+1.\n",
    "            t: current time step.\"\"\"\n",
    "        beta = self.betas[t]\n",
    "        return torch.sqrt(1 - beta) * img_prev + torch.sqrt(beta) * noise\n",
    "    \n",
    "    def denoising_step(self, img_next, noise_next, t, new_noise):\n",
    "        \"\"\"The inverse process of the forward_noise_step: predicts image at\n",
    "        step t from image at step t+1.\n",
    "        \n",
    "        Args:\n",
    "            img_next: image from step t+1.\n",
    "            noise_next: the (predicted) noise in img_next.\n",
    "            t: current time step.\n",
    "            new_noise: new pure gausssian noise N(0, 1) to add.\n",
    "        \"\"\"\n",
    "        beta = self.betas[t]\n",
    "        alpha_bar = self.alpha_bars[t]\n",
    "\n",
    "        mean_t = (\n",
    "            img_next - noise_next * beta / torch.sqrt(1 - alpha_bar)\n",
    "        ) / torch.sqrt(1 - beta)\n",
    "        img_t = mean_t + beta * new_noise\n",
    "\n",
    "        return img_t\n",
    "\n",
    "noiser = DiffusionNoiser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1996\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch[0] = theircode.scale_to_minus_one_to_one(batch[0])\n",
    "\n",
    "noisy_img = torch.randn_like(batch[0])\n",
    "for idx in reversed(range(1000)):\n",
    "    t = torch.tensor([idx])\n",
    "\n",
    "    # Pretending actual noise is predicted noise from model:\n",
    "    predicted_noise = noiser.noise_from_closed_form_noise(batch[0], noisy_img, t)\n",
    "\n",
    "    new_noise = torch.randn_like(batch[0])\n",
    "    noisy_img = noiser.denoising_step(noisy_img, predicted_noise, t, new_noise)\n",
    "\n",
    "noisy_img = theircode.reverse_scale_to_zero_to_one(noisy_img).squeeze()\n",
    "plt.imshow(noisy_img.detach().permute(1,2,0))\n",
    "\n",
    "# img2 = theircode.reverse_scale_to_zero_to_one(img2).squeeze()\n",
    "# plt.imshow(img2.detach().permute(1, 2, 0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all((1 - noiser.betas) == theircode.alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1996\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch[0] = theircode.scale_to_minus_one_to_one(batch[0])\n",
    "\n",
    "for idx in [100 * x + 1 for x in range(10)] + [999]:\n",
    "    img = batch[0]\n",
    "    t = torch.tensor([idx])\n",
    "    noised_img, noise = theircode.make_noisy(img, t)\n",
    "\n",
    "    # noised_img2 = noiser(img, noise, t)\n",
    "    # print(torch.all(noised_img == noised_img2))\n",
    "\n",
    "    # noise2 = noiser.noise_from_closed_form_noise(img, noised_img, t)\n",
    "    # print(torch.all(noise == noise2))\n",
    "    # print(torch.max(noise - noise2))\n",
    "    # print(torch.all(torch.isclose(noise, noise2)))\n",
    "\n",
    "    img2 = noiser.img_from_closed_form_noise(noised_img, noise, t)\n",
    "    print(torch.all(torch.isclose(img, img2)))\n",
    "    print(torch.max(img - img2))\n",
    "    \n",
    "    # img2 = theircode.reverse_scale_to_zero_to_one(img2).squeeze()\n",
    "    # plt.imshow(img2.detach().permute(1, 2, 0))\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # img = theircode.make_noisy(batch[0], torch.tensor([idx]))[0]\n",
    "    # img = theircode.reverse_scale_to_zero_to_one(img).squeeze()\n",
    "    # plt.imshow(img.detach().permute(1, 2, 0))\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
